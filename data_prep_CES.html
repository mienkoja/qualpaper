<!DOCTYPE html>
<!-- saved from url=(0014)about:internet -->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
<meta http-equiv="x-ua-compatible" content="IE=9" >

<title>Get Child Care Estimates from the CES</title>

<style type="text/css">
body, td {
   font-family: sans-serif;
   background-color: white;
   font-size: 12px;
   margin: 8px;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}

h1 { 
   font-size:2.2em; 
}

h2 { 
   font-size:1.8em; 
}

h3 { 
   font-size:1.4em; 
}

h4 { 
   font-size:1.0em; 
}

h5 { 
   font-size:0.9em; 
}

h6 { 
   font-size:0.8em; 
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre {	
   margin-top: 0;
   max-width: 95%;
   border: 1px solid #ccc;
   white-space: pre-wrap;
}

pre code {
   display: block; padding: 0.5em;
}

code.r, code.cpp {
   background-color: #F8F8F8;
}

table, td, th {
  border: none;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * { 
      background: transparent !important; 
      color: black !important; 
      filter:none !important; 
      -ms-filter: none !important; 
   }

   body { 
      font-size:12pt; 
      max-width:100%; 
   }
       
   a, a:visited { 
      text-decoration: underline; 
   }

   hr { 
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote { 
      padding-right: 1em; 
      page-break-inside: avoid; 
   }

   tr, img { 
      page-break-inside: avoid; 
   }

   img { 
      max-width: 100% !important; 
   }

   @page :left { 
      margin: 15mm 20mm 15mm 10mm; 
   }
     
   @page :right { 
      margin: 15mm 10mm 15mm 20mm; 
   }

   p, h2, h3 { 
      orphans: 3; widows: 3; 
   }

   h2, h3 { 
      page-break-after: avoid; 
   }
}

</style>

<!-- Styles for R syntax highlighter -->
<style type="text/css">
   pre .operator,
   pre .paren {
     color: rgb(104, 118, 135)
   }

   pre .literal {
     color: rgb(88, 72, 246)
   }

   pre .number {
     color: rgb(0, 0, 205);
   }

   pre .comment {
     color: rgb(76, 136, 107);
   }

   pre .keyword {
     color: rgb(0, 0, 255);
   }

   pre .identifier {
     color: rgb(0, 0, 0);
   }

   pre .string {
     color: rgb(3, 106, 7);
   }
</style>

<!-- R syntax highlighter -->
<script type="text/javascript">
var hljs=new function(){function m(p){return p.replace(/&/gm,"&amp;").replace(/</gm,"&lt;")}function f(r,q,p){return RegExp(q,"m"+(r.cI?"i":"")+(p?"g":""))}function b(r){for(var p=0;p<r.childNodes.length;p++){var q=r.childNodes[p];if(q.nodeName=="CODE"){return q}if(!(q.nodeType==3&&q.nodeValue.match(/\s+/))){break}}}function h(t,s){var p="";for(var r=0;r<t.childNodes.length;r++){if(t.childNodes[r].nodeType==3){var q=t.childNodes[r].nodeValue;if(s){q=q.replace(/\n/g,"")}p+=q}else{if(t.childNodes[r].nodeName=="BR"){p+="\n"}else{p+=h(t.childNodes[r])}}}if(/MSIE [678]/.test(navigator.userAgent)){p=p.replace(/\r/g,"\n")}return p}function a(s){var r=s.className.split(/\s+/);r=r.concat(s.parentNode.className.split(/\s+/));for(var q=0;q<r.length;q++){var p=r[q].replace(/^language-/,"");if(e[p]){return p}}}function c(q){var p=[];(function(s,t){for(var r=0;r<s.childNodes.length;r++){if(s.childNodes[r].nodeType==3){t+=s.childNodes[r].nodeValue.length}else{if(s.childNodes[r].nodeName=="BR"){t+=1}else{if(s.childNodes[r].nodeType==1){p.push({event:"start",offset:t,node:s.childNodes[r]});t=arguments.callee(s.childNodes[r],t);p.push({event:"stop",offset:t,node:s.childNodes[r]})}}}}return t})(q,0);return p}function k(y,w,x){var q=0;var z="";var s=[];function u(){if(y.length&&w.length){if(y[0].offset!=w[0].offset){return(y[0].offset<w[0].offset)?y:w}else{return w[0].event=="start"?y:w}}else{return y.length?y:w}}function t(D){var A="<"+D.nodeName.toLowerCase();for(var B=0;B<D.attributes.length;B++){var C=D.attributes[B];A+=" "+C.nodeName.toLowerCase();if(C.value!==undefined&&C.value!==false&&C.value!==null){A+='="'+m(C.value)+'"'}}return A+">"}while(y.length||w.length){var v=u().splice(0,1)[0];z+=m(x.substr(q,v.offset-q));q=v.offset;if(v.event=="start"){z+=t(v.node);s.push(v.node)}else{if(v.event=="stop"){var p,r=s.length;do{r--;p=s[r];z+=("</"+p.nodeName.toLowerCase()+">")}while(p!=v.node);s.splice(r,1);while(r<s.length){z+=t(s[r]);r++}}}}return z+m(x.substr(q))}function j(){function q(x,y,v){if(x.compiled){return}var u;var s=[];if(x.k){x.lR=f(y,x.l||hljs.IR,true);for(var w in x.k){if(!x.k.hasOwnProperty(w)){continue}if(x.k[w] instanceof Object){u=x.k[w]}else{u=x.k;w="keyword"}for(var r in u){if(!u.hasOwnProperty(r)){continue}x.k[r]=[w,u[r]];s.push(r)}}}if(!v){if(x.bWK){x.b="\\b("+s.join("|")+")\\s"}x.bR=f(y,x.b?x.b:"\\B|\\b");if(!x.e&&!x.eW){x.e="\\B|\\b"}if(x.e){x.eR=f(y,x.e)}}if(x.i){x.iR=f(y,x.i)}if(x.r===undefined){x.r=1}if(!x.c){x.c=[]}x.compiled=true;for(var t=0;t<x.c.length;t++){if(x.c[t]=="self"){x.c[t]=x}q(x.c[t],y,false)}if(x.starts){q(x.starts,y,false)}}for(var p in e){if(!e.hasOwnProperty(p)){continue}q(e[p].dM,e[p],true)}}function d(B,C){if(!j.called){j();j.called=true}function q(r,M){for(var L=0;L<M.c.length;L++){if((M.c[L].bR.exec(r)||[null])[0]==r){return M.c[L]}}}function v(L,r){if(D[L].e&&D[L].eR.test(r)){return 1}if(D[L].eW){var M=v(L-1,r);return M?M+1:0}return 0}function w(r,L){return L.i&&L.iR.test(r)}function K(N,O){var M=[];for(var L=0;L<N.c.length;L++){M.push(N.c[L].b)}var r=D.length-1;do{if(D[r].e){M.push(D[r].e)}r--}while(D[r+1].eW);if(N.i){M.push(N.i)}return f(O,M.join("|"),true)}function p(M,L){var N=D[D.length-1];if(!N.t){N.t=K(N,E)}N.t.lastIndex=L;var r=N.t.exec(M);return r?[M.substr(L,r.index-L),r[0],false]:[M.substr(L),"",true]}function z(N,r){var L=E.cI?r[0].toLowerCase():r[0];var M=N.k[L];if(M&&M instanceof Array){return M}return false}function F(L,P){L=m(L);if(!P.k){return L}var r="";var O=0;P.lR.lastIndex=0;var M=P.lR.exec(L);while(M){r+=L.substr(O,M.index-O);var N=z(P,M);if(N){x+=N[1];r+='<span class="'+N[0]+'">'+M[0]+"</span>"}else{r+=M[0]}O=P.lR.lastIndex;M=P.lR.exec(L)}return r+L.substr(O,L.length-O)}function J(L,M){if(M.sL&&e[M.sL]){var r=d(M.sL,L);x+=r.keyword_count;return r.value}else{return F(L,M)}}function I(M,r){var L=M.cN?'<span class="'+M.cN+'">':"";if(M.rB){y+=L;M.buffer=""}else{if(M.eB){y+=m(r)+L;M.buffer=""}else{y+=L;M.buffer=r}}D.push(M);A+=M.r}function G(N,M,Q){var R=D[D.length-1];if(Q){y+=J(R.buffer+N,R);return false}var P=q(M,R);if(P){y+=J(R.buffer+N,R);I(P,M);return P.rB}var L=v(D.length-1,M);if(L){var O=R.cN?"</span>":"";if(R.rE){y+=J(R.buffer+N,R)+O}else{if(R.eE){y+=J(R.buffer+N,R)+O+m(M)}else{y+=J(R.buffer+N+M,R)+O}}while(L>1){O=D[D.length-2].cN?"</span>":"";y+=O;L--;D.length--}var r=D[D.length-1];D.length--;D[D.length-1].buffer="";if(r.starts){I(r.starts,"")}return R.rE}if(w(M,R)){throw"Illegal"}}var E=e[B];var D=[E.dM];var A=0;var x=0;var y="";try{var s,u=0;E.dM.buffer="";do{s=p(C,u);var t=G(s[0],s[1],s[2]);u+=s[0].length;if(!t){u+=s[1].length}}while(!s[2]);if(D.length>1){throw"Illegal"}return{r:A,keyword_count:x,value:y}}catch(H){if(H=="Illegal"){return{r:0,keyword_count:0,value:m(C)}}else{throw H}}}function g(t){var p={keyword_count:0,r:0,value:m(t)};var r=p;for(var q in e){if(!e.hasOwnProperty(q)){continue}var s=d(q,t);s.language=q;if(s.keyword_count+s.r>r.keyword_count+r.r){r=s}if(s.keyword_count+s.r>p.keyword_count+p.r){r=p;p=s}}if(r.language){p.second_best=r}return p}function i(r,q,p){if(q){r=r.replace(/^((<[^>]+>|\t)+)/gm,function(t,w,v,u){return w.replace(/\t/g,q)})}if(p){r=r.replace(/\n/g,"<br>")}return r}function n(t,w,r){var x=h(t,r);var v=a(t);var y,s;if(v){y=d(v,x)}else{return}var q=c(t);if(q.length){s=document.createElement("pre");s.innerHTML=y.value;y.value=k(q,c(s),x)}y.value=i(y.value,w,r);var u=t.className;if(!u.match("(\\s|^)(language-)?"+v+"(\\s|$)")){u=u?(u+" "+v):v}if(/MSIE [678]/.test(navigator.userAgent)&&t.tagName=="CODE"&&t.parentNode.tagName=="PRE"){s=t.parentNode;var p=document.createElement("div");p.innerHTML="<pre><code>"+y.value+"</code></pre>";t=p.firstChild.firstChild;p.firstChild.cN=s.cN;s.parentNode.replaceChild(p.firstChild,s)}else{t.innerHTML=y.value}t.className=u;t.result={language:v,kw:y.keyword_count,re:y.r};if(y.second_best){t.second_best={language:y.second_best.language,kw:y.second_best.keyword_count,re:y.second_best.r}}}function o(){if(o.called){return}o.called=true;var r=document.getElementsByTagName("pre");for(var p=0;p<r.length;p++){var q=b(r[p]);if(q){n(q,hljs.tabReplace)}}}function l(){if(window.addEventListener){window.addEventListener("DOMContentLoaded",o,false);window.addEventListener("load",o,false)}else{if(window.attachEvent){window.attachEvent("onload",o)}else{window.onload=o}}}var e={};this.LANGUAGES=e;this.highlight=d;this.highlightAuto=g;this.fixMarkup=i;this.highlightBlock=n;this.initHighlighting=o;this.initHighlightingOnLoad=l;this.IR="[a-zA-Z][a-zA-Z0-9_]*";this.UIR="[a-zA-Z_][a-zA-Z0-9_]*";this.NR="\\b\\d+(\\.\\d+)?";this.CNR="\\b(0[xX][a-fA-F0-9]+|(\\d+(\\.\\d*)?|\\.\\d+)([eE][-+]?\\d+)?)";this.BNR="\\b(0b[01]+)";this.RSR="!|!=|!==|%|%=|&|&&|&=|\\*|\\*=|\\+|\\+=|,|\\.|-|-=|/|/=|:|;|<|<<|<<=|<=|=|==|===|>|>=|>>|>>=|>>>|>>>=|\\?|\\[|\\{|\\(|\\^|\\^=|\\||\\|=|\\|\\||~";this.ER="(?![\\s\\S])";this.BE={b:"\\\\.",r:0};this.ASM={cN:"string",b:"'",e:"'",i:"\\n",c:[this.BE],r:0};this.QSM={cN:"string",b:'"',e:'"',i:"\\n",c:[this.BE],r:0};this.CLCM={cN:"comment",b:"//",e:"$"};this.CBLCLM={cN:"comment",b:"/\\*",e:"\\*/"};this.HCM={cN:"comment",b:"#",e:"$"};this.NM={cN:"number",b:this.NR,r:0};this.CNM={cN:"number",b:this.CNR,r:0};this.BNM={cN:"number",b:this.BNR,r:0};this.inherit=function(r,s){var p={};for(var q in r){p[q]=r[q]}if(s){for(var q in s){p[q]=s[q]}}return p}}();hljs.LANGUAGES.cpp=function(){var a={keyword:{"false":1,"int":1,"float":1,"while":1,"private":1,"char":1,"catch":1,"export":1,virtual:1,operator:2,sizeof:2,dynamic_cast:2,typedef:2,const_cast:2,"const":1,struct:1,"for":1,static_cast:2,union:1,namespace:1,unsigned:1,"long":1,"throw":1,"volatile":2,"static":1,"protected":1,bool:1,template:1,mutable:1,"if":1,"public":1,friend:2,"do":1,"return":1,"goto":1,auto:1,"void":2,"enum":1,"else":1,"break":1,"new":1,extern:1,using:1,"true":1,"class":1,asm:1,"case":1,typeid:1,"short":1,reinterpret_cast:2,"default":1,"double":1,register:1,explicit:1,signed:1,typename:1,"try":1,"this":1,"switch":1,"continue":1,wchar_t:1,inline:1,"delete":1,alignof:1,char16_t:1,char32_t:1,constexpr:1,decltype:1,noexcept:1,nullptr:1,static_assert:1,thread_local:1,restrict:1,_Bool:1,complex:1},built_in:{std:1,string:1,cin:1,cout:1,cerr:1,clog:1,stringstream:1,istringstream:1,ostringstream:1,auto_ptr:1,deque:1,list:1,queue:1,stack:1,vector:1,map:1,set:1,bitset:1,multiset:1,multimap:1,unordered_set:1,unordered_map:1,unordered_multiset:1,unordered_multimap:1,array:1,shared_ptr:1}};return{dM:{k:a,i:"</",c:[hljs.CLCM,hljs.CBLCLM,hljs.QSM,{cN:"string",b:"'\\\\?.",e:"'",i:"."},{cN:"number",b:"\\b(\\d+(\\.\\d*)?|\\.\\d+)(u|U|l|L|ul|UL|f|F)"},hljs.CNM,{cN:"preprocessor",b:"#",e:"$"},{cN:"stl_container",b:"\\b(deque|list|queue|stack|vector|map|set|bitset|multiset|multimap|unordered_map|unordered_set|unordered_multiset|unordered_multimap|array)\\s*<",e:">",k:a,r:10,c:["self"]}]}}}();hljs.LANGUAGES.r={dM:{c:[hljs.HCM,{cN:"number",b:"\\b0[xX][0-9a-fA-F]+[Li]?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+(?:[eE][+\\-]?\\d*)?L\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+\\.(?!\\d)(?:i\\b)?",e:hljs.IMMEDIATE_RE,r:1},{cN:"number",b:"\\b\\d+(?:\\.\\d*)?(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\.\\d+(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"keyword",b:"(?:tryCatch|library|setGeneric|setGroupGeneric)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\.",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\d+(?![\\w.])",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\b(?:function)",e:hljs.IMMEDIATE_RE,r:2},{cN:"keyword",b:"(?:if|in|break|next|repeat|else|for|return|switch|while|try|stop|warning|require|attach|detach|source|setMethod|setClass)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"literal",b:"(?:NA|NA_integer_|NA_real_|NA_character_|NA_complex_)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"literal",b:"(?:NULL|TRUE|FALSE|T|F|Inf|NaN)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"identifier",b:"[a-zA-Z.][a-zA-Z0-9._]*\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"<\\-(?!\\s*\\d)",e:hljs.IMMEDIATE_RE,r:2},{cN:"operator",b:"\\->|<\\-",e:hljs.IMMEDIATE_RE,r:1},{cN:"operator",b:"%%|~",e:hljs.IMMEDIATE_RE},{cN:"operator",b:">=|<=|==|!=|\\|\\||&&|=|\\+|\\-|\\*|/|\\^|>|<|!|&|\\||\\$|:",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"%",e:"%",i:"\\n",r:1},{cN:"identifier",b:"`",e:"`",r:0},{cN:"string",b:'"',e:'"',c:[hljs.BE],r:0},{cN:"string",b:"'",e:"'",c:[hljs.BE],r:0},{cN:"paren",b:"[[({\\])}]",e:hljs.IMMEDIATE_RE,r:0}]}};
hljs.initHighlightingOnLoad();
</script>




</head>

<body>
<h1>Get Child Care Estimates from the CES</h1>

<p>This document is used to calculate an integrated mean and standard deviation for child care expenditures as reported in the consumer expenditure survey. The script used here is a hack of the scripts written by <a href="https://github.com/ajdamico/usgsd/tree/master/Consumer%20Expenditure%20Survey">ajdamico</a> and available for use the following <a href="https://github.com/ajdamico/usgsd/tree/master/Consumer%20Expenditure%20Survey">link</a>. The files were downloaded using scripts in that repo and the directories identified in the following scripts assume that the user has a directory structure that matches those resulting from the <a href="https://github.com/ajdamico/usgsd/tree/master/Consumer%20Expenditure%20Survey">ajdamico</a> download scripts. The source scripts were designed to port the &ldquo;Integrated Mean and SE.sas&rdquo; code to R. The original SAS program is described by the BLS <a href="www.bls.gov/cex/2010/csxdiary.pdf">here</a>. The code here is mostly unchanged except to streamline for our focus on childcare expenditures.  </p>

<h2>Preliminary Steps</h2>

<p>The following code clears our memory, sets our working directory (as created by the <a href="https://github.com/ajdamico/usgsd/tree/master/Consumer%20Expenditure%20Survey">ajdamico</a> scripts), and loads some libraries that are required for these initial steps. </p>

<pre><code class="r"># clear memory
rm(list = ls(all = TRUE))

# setwd(&#39;C:/Users/mienkoja/Dropbox/qualpaper/CES&#39;)
setwd(&quot;~/Dropbox/qualpaper/CES&quot;)

# turn off scientific notation in most output
options(scipen = 20)

require(stringr)  # load stringr package (manipulates character strings easily)
</code></pre>

<pre><code>## Loading required package: stringr
</code></pre>

<pre><code class="r">require(reshape2)  # load reshape2 package (transposes data frames quickly)
</code></pre>

<pre><code>## Loading required package: reshape2
</code></pre>

<pre><code class="r">require(sqldf)  # load the sqldf package (enables sql queries on data frames)
</code></pre>

<pre><code>## Loading required package: sqldf
## Loading required package: gsubfn
## Loading required package: proto
## Loading required namespace: tcltk
## Loading required package: RSQLite
## Loading required package: DBI
## Loading required package: RSQLite.extfuns
</code></pre>

<pre><code class="r">require(RSQLite)  # load RSQLite package (creates database files in R)
require(plyr)  # load plyr package (allows for the merging of unequal dataframes via rbind.fill)
</code></pre>

<pre><code>## Loading required package: plyr
</code></pre>

<h2>Create Stub File</h2>

<p>This chunk of code creates a &ldquo;stub parameter file&rdquo; and formats. Some of this code is probably overkill and can be streamlined at some point. The main change I have made to the original code here is to subset the file to only include expenditure data (i.e. <code>group == &quot;EXPEND&quot;</code>) and only include childcare expenditures (i.e. <code>ucc %in% c( &quot;670310&quot; , &quot;340212&quot; , &quot;340211&quot;)</code>).</p>

<pre><code class="r"># st &lt;-
# readLines(&#39;C:/Users/mienkoja/Dropbox/qp_analysis/CES/2004/docs/Programs
# 2004/IntStub2004.txt&#39;)
st &lt;- readLines(&quot;~/Dropbox/qualpaper/CES/2004/docs/Programs 2004/Intstub2004.txt&quot;)

# create a temporary file on the local disk..
tf &lt;- tempfile()

# only keep rows starting with a one
st &lt;- st[substr(st, 1, 1) == &quot;1&quot;]

# replace these two tabs with seven spaces instead
st &lt;- gsub(&quot;\t\t&quot;, &quot;       &quot;, st)

# save to the temporary file created above
writeLines(st, tf)

# read that temporary file (the slightly modified IntStubYYYY.txt file) into
# memory as an R data frame
stubfile &lt;- read.fwf(tf, width = c(1, -2, 1, -2, 60, -3, 6, -4, 1, -5, 7), col.names = c(&quot;type&quot;, 
    &quot;level&quot;, &quot;title&quot;, &quot;ucc&quot;, &quot;survey&quot;, &quot;group&quot;))

# eliminate all whitespace (on both sides) in the group column
stubfile$group &lt;- str_trim(as.character(stubfile$group))

# subset the stubfile to only contain records a) in the four groups below b)
# where the survey column isn&#39;t &#39;T&#39; c) where ucc indicates childcare
stubfile &lt;- subset(stubfile, ucc %in% c(&quot;670310&quot;, &quot;340212&quot;, &quot;340211&quot;) &amp; survey != 
    &quot;T&quot; &amp; group == &quot;EXPEND&quot;)

# remove the rownames from the stubfile (after subsetting, rows maintain
# their original numbering.  this action wipes it out.)
rownames(stubfile) &lt;- NULL

# create a new count variable starting at 10,000
stubfile$count &lt;- 10000 + (1:nrow(stubfile))

# create a new line variable by concatenating the count and level variables
stubfile$line &lt;- paste0(stubfile$count, stubfile$level)

# start with a character vector with ten blank strings..
curlines &lt;- rep(&quot;&quot;, 10)

# initiate a matrix containing the line numbers of each expenditure category
aggfmt1 &lt;- matrix(nrow = nrow(stubfile), ncol = 10)

# loop through each record in the stubfile..
for (i in seq(nrow(stubfile))) {

    # if the &#39;ucc&#39; variable is numeric (that is, as.numeric() does not return a
    # missing NA value)
    if (!is.na(as.numeric(as.character(stubfile[i, &quot;ucc&quot;])))) {

        # save the line number as the last element in the character vector
        curlines[10] &lt;- stubfile[i, &quot;line&quot;]

        # otherwise blank it out
    } else curlines[10] &lt;- &quot;&quot;

    # store the current line and level in separate atomic variables
    curlevel &lt;- stubfile[i, &quot;level&quot;]
    curline &lt;- stubfile[i, &quot;line&quot;]

    # write the current line inside the length-ten character vector
    curlines[curlevel] &lt;- curline

    # if the current level is 1-8, blank out everything above it up to nine
    if (curlevel &lt; 9) 
        curlines[(curlevel + 1):9] &lt;- &quot;&quot;

    # remove actual value
    savelines &lt;- curlines
    savelines[curlevel] &lt;- &quot;&quot;

    # overwrite the entire row with the character vector of length ten
    aggfmt1[i, ] &lt;- savelines
}

# convert the matrix to a data frame..
aggfmt1 &lt;- data.frame(aggfmt1)

# ..and name its columns line1 - line10
names(aggfmt1) &lt;- paste0(&quot;line&quot;, 1:10)

# tack on the ucc and line columns from the stubfile (which has the same
# number of records)
aggfmt1 &lt;- cbind(aggfmt1, stubfile[, c(&quot;ucc&quot;, &quot;line&quot;)])

# remove records where the ucc is numeric
aggfmt1 &lt;- subset(aggfmt1, !is.na(as.numeric(as.character(ucc))))

# order the data frame by ucc
aggfmt1 &lt;- aggfmt1[order(aggfmt1$ucc), ]

# rename line to compare
aggfmt1$compare &lt;- aggfmt1$line
aggfmt1$line &lt;- NULL

# reset the row names/numbers
rownames(aggfmt1) &lt;- NULL

# transpose the data, holding ucc and compare
aggfmt2 &lt;- melt(aggfmt1, id = c(&quot;ucc&quot;, &quot;compare&quot;))
names(aggfmt2)[4] &lt;- &quot;line&quot;

# retain the ucc-to-line crosswalk wherever the &#39;line&#39; variable is not blank
aggfmt &lt;- subset(aggfmt2, line != &quot;&quot;, select = c(&quot;ucc&quot;, &quot;line&quot;))

# re-order the data frame by ucc
aggfmt &lt;- aggfmt[order(aggfmt$ucc), ]
</code></pre>

<h2>Read in All Data</h2>

<p>This chunk of code reads in all of the required data from the interview and diary files, creates an <code>mo_scope</code> variable, reads in the interview <code>mtab</code> and <code>itab</code> files along with the diary expenditure and <code>dtab</code> files. Finally, the data are merged to derive the appropriately weighted childcare expenditures. Again, some of this code is probably overkill and can be streamlined at some point. Note the strategic use of <code>gc()</code> throughout the code to clean up the RAM. This may be unecessary on some machines but as I was trying to </p>

<pre><code class="r"># read in the four &#39;fmld&#39; files in the diary folder
# this contains all family diary records

load(&quot;2004/diary/fmld041.rda&quot;)
load(&quot;2004/diary/fmld042.rda&quot;)
load(&quot;2004/diary/fmld043.rda&quot;)
load(&quot;2004/diary/fmld044.rda&quot;)

d &lt;- rbind(fmld041, fmld042, fmld043, fmld044)

# clear up RAM
gc()


# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # 
# read in the five quarters of family data files (fmli)

# load all five R data files (.rda)
load(&quot;2004/intrvw/fmli041x.rda&quot;) 
load(&quot;2004/intrvw/fmli042.rda&quot;) 
load(&quot;2004/intrvw/fmli043.rda&quot;) 
load(&quot;2004/intrvw/fmli044.rda&quot;) 
load(&quot;2004/intrvw/fmli051.rda&quot;) 

# copy the fmliYY1x data frame to another data frame &#39;x&#39;

fmli041x$qtr &lt;- 1
fmli042$qtr &lt;- 2
fmli043$qtr &lt;- 3
fmli044$qtr &lt;- 4
fmli051$qtr &lt;- 5

# stack all five fmli# files together, into a large single data frame &#39;f&#39;
f &lt;- rbind.fill( fmli041x
                 ,fmli042
                 ,fmli043
                 ,fmli044
                 ,fmli051)

# only select families with young children 
f &lt;- subset(f, f$as_comp5 &gt; 0)

# delete all of the independent data frames from memory
rm( fmli041x
    ,fmli042
    ,fmli043
    ,fmli044
    ,fmli051)

# clear up RAM
gc()

# create a mo_scope variable in this large new family data frame
f &lt;- 
  transform( 
    f ,
    mo_scope = 
      # the first quarter should be interview month minus one
      ifelse( qtr %in% 1 , as.numeric( qintrvmo ) - 1 ,
              # the final quarter should be four minus the interview month
              ifelse( qtr %in% 5 , ( 4 - as.numeric( qintrvmo )  ) ,
                      # all other quarters should have a 3
                      3 ) ) 
  )

# the source column for family records should be &quot;I&quot; (interview) throughout
f$source &lt;- &quot;I&quot;

# the mo_scope variable for the &#39;d&#39; (fmld) data frame should be 3 for all records
d$mo_scope &lt;- 3
# ..and the source should be &quot;D&quot; throughout
d$source &lt;- &quot;D&quot;

# create a character vector containing 45 variable names (wtrep01, wtrep02, ... wtrep44 and finlwt21)
wtrep &lt;- c( paste0( &quot;wtrep&quot; , str_pad( 1:44 , 2 , pad = &quot;0&quot; ) ) , &quot;finlwt21&quot; )

# create a second character vector containing 45 variable names (repwt1, repwt2, .. repwt44, repwt45)
repwt &lt;- paste0( &quot;repwt&quot; , 1:45 )

# create a third character vector that will be used to define which columns to keep
f.d.vars &lt;- c( wtrep , &quot;mo_scope&quot; , &quot;inclass&quot; , &quot;newid&quot; , &quot;source&quot; )

# stack the family interview and diary records together,
# keeping only the 45 wtrep columns, plus the additional four written above
fmly &lt;- rbind( f[ , f.d.vars ] , d[ , f.d.vars ] )

# remove data frames &#39;f&#39; and &#39;d&#39; from memory
rm( f , d )

# clear up RAM
gc()

# loop through the 45 wtrep variables in the newly-stacked fmly data frame..
for ( i in 1:45 ){

  # convert all columns to numeric
  fmly[ , wtrep[ i ] ] &lt;- as.numeric( as.character( fmly[ , wtrep[ i ] ] ) )

  # replace all missings with zeroes
  fmly[ is.na( fmly[ , wtrep[ i ] ] ) , wtrep[ i ] ] &lt;- 0

  # multiply by months in scope, then divide by 12 (months)
  fmly[ , repwt[ i ] ] &lt;- ( fmly[ , wtrep[ i ] ] * fmly[ , &quot;mo_scope&quot; ] / 12 )
}

load(&quot;2004/diary/expd041.rda&quot;) 
load(&quot;2004/diary/expd042.rda&quot;) 
load(&quot;2004/diary/expd043.rda&quot;) 
load(&quot;2004/diary/expd044.rda&quot;) 

expd &lt;- rbind( expd041
              ,expd042
              ,expd043
              ,expd044)

rm( expd041
    ,expd042
    ,expd043
    ,expd044)

gc()

load(&quot;2004/diary/dtbd041.rda&quot;) 
load(&quot;2004/diary/dtbd042.rda&quot;) 
load(&quot;2004/diary/dtbd043.rda&quot;) 
load(&quot;2004/diary/dtbd044.rda&quot;) 

dtbd &lt;- rbind( dtbd041
              ,dtbd042
              ,dtbd043
              ,dtbd044)

rm( dtbd041
               ,dtbd042
               ,dtbd043
               ,dtbd044)

gc()

load(&quot;2004/intrvw/mtbi041x.rda&quot;) 
load(&quot;2004/intrvw/mtbi042.rda&quot;) 
load(&quot;2004/intrvw/mtbi043.rda&quot;) 
load(&quot;2004/intrvw/mtbi044.rda&quot;) 
load(&quot;2004/intrvw/mtbi051.rda&quot;) 

mtbi &lt;- rbind( mtbi041x
               ,mtbi042
               ,mtbi043
               ,mtbi044
               ,mtbi051)

rm( mtbi041x
               ,mtbi042
               ,mtbi043
               ,mtbi044
               ,mtbi051)

gc()

load(&quot;2004/intrvw/itbi041x.rda&quot;) 
load(&quot;2004/intrvw/itbi042.rda&quot;) 
load(&quot;2004/intrvw/itbi043.rda&quot;) 
load(&quot;2004/intrvw/itbi044.rda&quot;) 
load(&quot;2004/intrvw/itbi051.rda&quot;) 

itbi &lt;- rbind( itbi041x
                ,itbi042
                ,itbi043
                ,itbi044
                ,itbi051)

rm( itbi041x
               ,itbi042
               ,itbi043
               ,itbi044
               ,itbi051)


# clear up RAM
gc()

# copy (effectively rename) the &#39;amount&#39; and &#39;value&#39; columns to &#39;cost&#39;
dtbd$cost &lt;- dtbd$amount
itbi$cost &lt;- itbi$value

# limit the itbi and mtbi (interview) data frames to records from the current year with pubflags of two
expend.itbi &lt;- subset( itbi , pubflag == 2 &amp; refyr == 2004 )
expend.mtbi &lt;- subset( mtbi , pubflag == 2 &amp; ref_yr == 2004 )

# choose which columns to keep when stacking these data frames
edmi.vars &lt;- c( &quot;newid&quot; , &quot;ucc&quot; , &quot;cost&quot; )

# stack the itbi and mtbi files
expend.im &lt;- 
  rbind( 
    expend.itbi[ , edmi.vars ] , 
    expend.mtbi[ , edmi.vars ] 
  )

# create a new &#39;source&#39; column, with &quot;I&quot; (interview) throughout
expend.im$source &lt;- &quot;I&quot;

# limit the expenditure diary to the same short list of variables, and only with a pubflag of two
expend.expd &lt;- subset( expd , pub_flag == 2 , select = edmi.vars )

# create a new &#39;source&#39; column, with &quot;D&quot; (diary) throughout
expend.expd$source &lt;- &quot;D&quot;

# multiply the diary records&#39; cost column by 13
expend.expd$cost &lt;- expend.expd$cost * 13

# stack the interview and diary expenditure records together
expend &lt;- rbind( expend.im , expend.expd )

# remove all of these smaller R data frames from memory
rm( itbi , mtbi , expend.itbi , expend.mtbi , expend.im , expend.expd )

# clear up RAM
gc()

# order the expenditure data frame by the unique consumer unit id (newid)
expend &lt;- expend[ order( expend$newid ) , ]

#only grab the uccs we are interested in
expend &lt;- subset(expend, expend$ucc %in% c( &quot;670310&quot; , &quot;340212&quot; , &quot;340211&quot;))

# create a character vector rcost1 - rcost45
rcost &lt;- paste0( &quot;rcost&quot; , 1:45 )

# partially build the sql string, multiply each &#39;wtrep##&#39; variable by &#39;cost&#39; and rename it &#39;rcost##&#39;
wtrep.cost &lt;- paste0( &quot;( b.cost * a.&quot; , wtrep , &quot; ) as &quot; , rcost , collapse = &quot;, &quot; )

# build the entire sql string..
sql.line &lt;- 
  paste( 
    # creating a new &#39;pubfile&#39; table, saving a few columns from each table
    &quot;select a.newid , a.inclass , b.source , b.ucc ,&quot; ,
    wtrep.cost ,
    # joining the family and expenditure tables on two fields
    &quot;from fmly a inner join expend b on a.newid = b.newid AND a.source = b.source&quot; 
  )

pubfile &lt;- sqldf(sql.line)
save.image(&quot;~/Dropbox/qualpaper/cc.RData&quot;)
</code></pre>

<p>Note the <code>save.image()</code> at the end of the previous chunk. I am not currently evaluating this chunk when I compile my markdown to HTML. The code runs fine outside of knitr, but knitr has a yet undiagnosed problem in trying to load the compressed data files. Once this problem is fixed, the following chunk will be unecessary.  </p>

<pre><code class="r">load(&quot;~/Dropbox/qualpaper/cc.RData&quot;)
</code></pre>

<h2>Calculate Aggregate Expenditures </h2>

<p>This next chunk sums all 45 weight variables to derive replicate populations. These weights are then used to calculate aggregate expenditures for each ucc. </p>

<pre><code class="r">
# create a character vector containing 45 variable names (rpop1, rpop2, ... rpop44, rpop45)
rpop &lt;- paste0( &quot;rpop&quot; , 1:45 )

# partially build the sql string, sum each &#39;repwt##&#39; variable into &#39;rpop##&#39;
rpop.sums &lt;- paste( &quot;sum( &quot; , repwt , &quot;) as &quot; , rpop , collapse = &quot;, &quot; )

# partially build the sql string, sum each &#39;rcost##&#39; variable into the same column name, &#39;rcost##&#39;
rcost.sums &lt;- paste( &quot;sum( &quot; , rcost , &quot;) as &quot; , rcost , collapse = &quot;, &quot; )

# create a total population sum (not grouping by &#39;inclass&#39; -- instead assigning everyone to &#39;10&#39;)
pop.all &lt;- sqldf(paste( &quot;select 10 as inclass, source, &quot; , rpop.sums , &quot;from fmly group by source&quot;))
</code></pre>

<pre><code>## Loading required package: tcltk
</code></pre>

<pre><code class="r">
# create a population sum, grouped by inclass (the income class variable)
pop.by &lt;- sqldf(paste( &quot;select inclass, source,&quot; , rpop.sums , &quot;from fmly group by inclass, source&quot;))

# stack the overall and grouped-by population tables
pop &lt;- rbind( pop.all , pop.by )


# create the right hand side of the aggregate expenditures table
aggright &lt;-
  # use a sql query from the temporary database (.db) file
  sqldf(  
    paste( 
      # group by inclass (income class) and a few other variables
      &quot;select inclass, source, ucc,&quot; , 
      rcost.sums , 
      &quot;from pubfile group by source , inclass , ucc&quot; ,
      # the &#39;union&#39; command stacks the grouped data (above) with the overall data (below)
      &quot;union&quot; ,
      # do not group by inclass, instead assign everyone as an inclass of ten
      &quot;select &#39;10&#39; as inclass, source , ucc,&quot; , 
      rcost.sums , 
      &quot;from pubfile group by source , ucc&quot; 
    )
  )

# create three character vectors containing every combination of..

# the expenditure table&#39;s source variable
so &lt;- names( table( expend$source ) )
# the expenditure table&#39;s ucc variable
uc &lt;- names( table( expend$ucc ) )
# the family table&#39;s inclass (income class) variable
cl &lt;- names( table( fmly[ , &#39;inclass&#39; ] ) )
# add a &#39;10&#39; - overall category to the inclass variable
cl &lt;- c( cl , &quot;10&quot; )

# now create a data frame containing every combination of every variable in the above three vectors
# (this matches the &#39;COMPLETETYPES&#39; option in a sas proc summary call
aggleft &lt;- expand.grid( so , uc , cl )

# name the columns in this new data frame appropriately
names( aggleft ) &lt;- c( &#39;source&#39; , &#39;ucc&#39; , &#39;inclass&#39; )

# perform a left-join, keeping all records in the left hand side, even ones without a match
agg &lt;- merge( aggleft , aggright , all.x = TRUE )
</code></pre>

<h2>Calculate Mean and Standard Errors </h2>

<p>This chunk combines all of the data formatted above and calculates means by dividing the aggregates by the relevant source population (i.e. diary vs. interview). Expenditure means are then summed per ucc for each income category. Standard errors are calculated using the BLS replicate formula identified in the original SAS code referenced above. </p>

<pre><code class="r">
# create a character vector containing mean1, mean2, ... , mean45
means &lt;- paste0(&quot;mean&quot;, 1:45)

# merge the population and weighted aggregate data tables together
avgs1 &lt;- merge(pop, agg)

# loop through all 45 weights..
for (i in 1:45) {
    # calculate the new &#39;mean##&#39; variable by dividing the expenditure (rcost##)
    # by the population (rpop##) variables
    avgs1[, means[i]] &lt;- (avgs1[, rcost[i]]/avgs1[, rpop[i]])

    # convert all missing (NA) mean values to zeroes
    avgs1[is.na(avgs1[, means[i]]), means[i]] &lt;- 0
}

# keep only a few columns, plus the 45 &#39;mean##&#39; columns
avgs1 &lt;- avgs1[, c(&quot;source&quot;, &quot;inclass&quot;, &quot;ucc&quot;, means)]

# partially build the sql string, sum each &#39;mean##&#39; variable into the same
# column name, &#39;mean##&#39;
avgs.sums &lt;- paste(&quot;sum( &quot;, means, &quot;) as &quot;, means, collapse = &quot;, &quot;)

# merge on the &#39;line&#39; column from the &#39;aggfmt&#39; data frame
avgs3 &lt;- merge(avgs1, aggfmt)

# remove duplicate records from the data frame
avgs3 &lt;- sqldf(&quot;select distinct * from avgs3&quot;)

# construct the full sql string, grouping each sum by inclass (income class)
# and line (expenditure category)
sql.avgs &lt;- paste(&quot;select inclass, line,&quot;, avgs.sums, &quot;from avgs3 group by inclass, line&quot;)

# execute the sql string
avgs2 &lt;- sqldf(sql.avgs)

# copy the avgs2 table over to a new data frame named &#39;se&#39;
se &lt;- avgs2

# create a character vector containing 44 strings, diff1, diff2, .. diff44
diffs &lt;- paste0(&quot;diff&quot;, 1:44)

# loop through the numbers 1-44, and calculate the diff column as the square
# of the difference between the current mean and the 45th mean
for (i in 1:44) se[, diffs[i]] &lt;- (se[, means[i]] - se[, &quot;mean45&quot;])^2
# for example, when i is 30, diff30 = ( mean30 - mean45 )^2

# save the 45th mean as the overall mean
se$mean &lt;- se$mean45

# sum the differences, divide by 44 to calculate the variance, then take the
# square root to calculate the standard error
se$se &lt;- sqrt(rowSums(se[, diffs])/44)

# retain only a few important columns in the se data frame
se &lt;- se[, c(&quot;inclass&quot;, &quot;line&quot;, &quot;mean&quot;, &quot;se&quot;)]

# transpose the se data frame by line and inclass, storing the value of the
# mean column save this result into a new data frame &#39;tab1m&#39;
tab1m &lt;- dcast(se, line ~ inclass, mean, value.var = &quot;mean&quot;)

# transpose the se data frame by line and inclass, storing the value of the
# se column save this result into a new data frame &#39;tab1s&#39;
tab1s &lt;- dcast(se, line ~ inclass, mean, value.var = &quot;se&quot;)

# create new columns in each data table, designating &#39;mean&#39; and &#39;se&#39;
tab1m$estimate &lt;- &quot;MEAN&quot;
tab1s$estimate &lt;- &quot;SE&quot;

# stack the mean and se tables together, into a new data frame called tab1
tab1 &lt;- rbind(tab1m, tab1s)
</code></pre>

<h2>Save Data for Later Analysis </h2>

<pre><code class="r">cc_by_inc &lt;- tab1
# extract means for own home, other home, and center child care
cc_own &lt;- tab1[1, 11] * 0.91
cc_oth &lt;- tab1[2, 11] * 0.91
cc_ctr &lt;- tab1[3, 11] * 0.91

cc_own_se &lt;- tab1[4, 11] * 0.91
cc_oth_se &lt;- tab1[5, 11] * 0.91
cc_ctr_se &lt;- tab1[6, 11] * 0.91

cc &lt;- c(&quot;cc_own&quot;, &quot;cc_oth&quot;, &quot;cc_ctr&quot;, &quot;cc_own_se&quot;, &quot;cc_oth_se&quot;, &quot;cc_ctr_se&quot;, 
    &quot;cc_by_inc&quot;)

rm(list = setdiff(ls(), cc))
save.image(&quot;~/Dropbox/qualpaper/cc_out.RData&quot;)
</code></pre>

</body>

</html>

